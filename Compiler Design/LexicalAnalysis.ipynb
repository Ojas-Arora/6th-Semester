{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pvfOURXLHu40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56e7a38-ae02-412d-a83c-05ea7e173f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the multi-line code (type 'END' to finish):\n",
            "int main(){\n",
            "int a =10;\n",
            "int b=20;\n",
            "printf(\"Sum is: %d\" , a+b);\n",
            "return 0;\n",
            "}\n",
            "END\n",
            "\n",
            "Lexical Analysis Result:\n",
            "\n",
            "Lexeme\t\tToken\n",
            "------------------------------\n",
            "int            KEYWORD\n",
            "main           IDENTIFIER\n",
            "(              SPECIAL_SYMBOL\n",
            ")              SPECIAL_SYMBOL\n",
            "{              SPECIAL_SYMBOL\n",
            "int            KEYWORD\n",
            "a              IDENTIFIER\n",
            "=              OPERATOR\n",
            "10             NUMBER\n",
            ";              SPECIAL_SYMBOL\n",
            "int            KEYWORD\n",
            "b              IDENTIFIER\n",
            "=              OPERATOR\n",
            "20             NUMBER\n",
            ";              SPECIAL_SYMBOL\n",
            "printf         IDENTIFIER\n",
            "(              SPECIAL_SYMBOL\n",
            "\"Sum is: %d\"   STRING_LITERAL\n",
            ",              SPECIAL_SYMBOL\n",
            "a              IDENTIFIER\n",
            "+              OPERATOR\n",
            "b              IDENTIFIER\n",
            ")              SPECIAL_SYMBOL\n",
            ";              SPECIAL_SYMBOL\n",
            "return         KEYWORD\n",
            "0              NUMBER\n",
            ";              SPECIAL_SYMBOL\n",
            "}              SPECIAL_SYMBOL\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "token_specification = [\n",
        "    ('KEYWORD', r'\\b(int|float|char|double|long|short|return)\\b'),\n",
        "    ('IDENTIFIER', r'[a-zA-Z_][a-zA-Z0-9_]*'),\n",
        "    ('OPERATOR', r'[=+\\-*/]'),\n",
        "    ('NUMBER', r'\\d+'),\n",
        "    ('SPECIAL_SYMBOL', r'[;{}()&,]'),\n",
        "    ('STRING_LITERAL', r'\"[^\"]*\"'),\n",
        "    ('SKIP', r'[ \\t\\n]+'),\n",
        "    ('MISMATCH', r'.'),\n",
        "]\n",
        "\n",
        "token_regex = '|'.join(f'(?P<{name}>{pattern})' for name, pattern in token_specification)\n",
        "\n",
        "\n",
        "def lexical_analyze(expression):\n",
        "    tokens = []\n",
        "    for match in re.finditer(token_regex, expression):\n",
        "        token_type = match.lastgroup\n",
        "        token_value = match.group()\n",
        "\n",
        "        if token_type == 'SKIP':\n",
        "            continue\n",
        "        elif token_type == 'MISMATCH':\n",
        "            raise SyntaxError(f\"Unexpected character: {token_value}\")\n",
        "        else:\n",
        "            tokens.append((token_value, token_type))\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def display_tokens(tokens):\n",
        "    print(\"\\nLexeme\\t\\tToken\")\n",
        "    print(\"-\" * 30)\n",
        "    for lexeme, token_type in tokens:\n",
        "        print(f\"{lexeme:<15}{token_type}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Enter the multi-line code (type 'END' to finish):\")\n",
        "    lines = []\n",
        "    while True:\n",
        "        line = input()\n",
        "        if line.strip() == \"END\":\n",
        "            break\n",
        "        lines.append(line)\n",
        "\n",
        "    code = '\\n'.join(lines)\n",
        "    try:\n",
        "        tokens = lexical_analyze(code)\n",
        "        print(\"\\nLexical Analysis Result:\")\n",
        "        display_tokens(tokens)\n",
        "    except SyntaxError as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iayfCEyhMBv2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}